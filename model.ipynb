{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops \n",
    "\n",
    "from collections import Counter \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from _operator import index\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read processed data\n",
    "data_X = pd.read_csv('process-dataset/train_X.csv',dtype=object)\n",
    "data_Y = pd.read_csv('process-dataset/train_Y.csv',dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read X and Y \n",
    "train_X = data_X['article']\n",
    "train_Y = data_Y['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_X['article'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.astype(str)\n",
    "train_Y = train_Y.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data columns id data actual create date sample data id data actual create date 111 open 20180228 111 comment 20180228 111 resolved 20180301 222 open 20180302 222 comment 20180303 222 resolved 20180305 need within single id eg 111 need create column called end date takes actual create date next row makes end date previous entry unless entry resolved end date create date data looks like following id data actual create date end date 111 open 20180228 20180228 111 comment 20180228 20180301 111 resolved 20180301 20180301 222 open 20180302 20180303 222 comment 20180303 20180305 222 resolved 20180305 20180305 apparently need provide queries run far according strawberry select aissueid id bshortid atitle issue_description arequest_type asite bpath b data b actual create date sim_fe left join sim_fe_audit_data b bissueid aissueid b data open comment audit feasibility wouldeep dive scoping pending others awaiting requester info aresolved arequest_type like capacity gets data need unique key though data audit trail things happened id unique project multiple things show data project id column get multiple ids short id issue description request_type site path data visualization side could left terms query function likewise unique function query essentially create stop date steps process currently start date actual create date step thus ability assign next step actual create date previous step ending date tried tweaking proposed answer every way think work intended go 255 rows base query 143k next try select aissueid id atitle issue_description arequest_type asite b data b actual create date b end date brank sim_fe left join select issueid data actual create date rank case id issueid 0 else rank1 end rank id issueid issueid1 end date select rank 1 r select id 1 select sim_fe_audit_data data open comment audit feasibility wouldeep dive scoping pending others awaiting requester info aresolved order issueid actual create date inner join select issueid id2 actual create date end date sim_fe_audit_data tid2 sissueid 1 b bissueid aissueid request_type like capacity one strange basically end dates duplicated repeatedly causes 255 rows become 39814 rows join wrong hopefully sqlfiddle right http sqlfiddlecom 9788b71'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[35487]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'(\\s\\d+\\s)',' ',text)\n",
    "    text = re.sub(r'[0-9]*','',text)\n",
    "    \n",
    "    text = text.split()\n",
    "    text = \" \".join([w for w in text if len(w) >= 2])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, RepeatVector, TimeDistributed\n",
    "\n",
    "## Plotly\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=True)\n",
    "# Others\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import *\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = clean_text(train_X[35487])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create X sequence\n",
    "vocabulary_size = 10000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(train_X)\n",
    "seq_x = pad_sequences(sequences,maxlen=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   3,  195,  391,  118,   22,  329,  131,   13, 6307,  554,   88,\n",
       "        170, 1640,   86,    7, 9893,  727,    7,   86, 2184,   60,  639,\n",
       "         96, 1180,  244,  312,  136,   96,  722,   60,   96,  566, 1532,\n",
       "       2611, 1136,  214,  566,  722,   60,   96,  698,  566, 3418,   96,\n",
       "         69, 6586,  364,  232,   38,  288,   64, 2546,  262,  271,  375,\n",
       "         86,  355,  214,   93,   53,    3,  195,  391, 6677,   22,   57,\n",
       "         13,   57,  722,   60,   96,   57,   47,   96, 6138, 4059,  170,\n",
       "        394,   53,   13,  722,   60,   96, 2243,  121,    3,   59, 2243,\n",
       "         47, 2243,    3,   47,   96,   53, 2243,  192,   53,    3,   53,\n",
       "       6138, 4059, 4943,   13,   13,  194,  654, 4943, 2907, 1240,  199,\n",
       "        173,  722,   60,   96,  776,  394,   53,    3,  722,   60,   96,\n",
       "         47,   96, 6138, 4059, 4943,   13, 2465,   57,  118,   22,   14,\n",
       "       3632,   30, 1334,  614,   47, 1279, 4328, 5955, 1628,  271, 1983,\n",
       "        271,  394,  185, 2862,  135,   32,   57])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_x[35487]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tried 69\n",
      "audit 4943\n",
      "audit 4943\n",
      "audit 4943\n",
      "issue 195\n",
      "issue 195\n",
      "r 192\n",
      "id 3\n",
      "id 3\n",
      "id 3\n",
      "id 3\n",
      "id 3\n",
      "id 3\n",
      "stop 639\n",
      "one 30\n",
      "thus 1532\n",
      "think 288\n",
      "unique 727\n",
      "arequest 6677\n",
      "path 131\n",
      "description 391\n",
      "description 391\n",
      "step 566\n",
      "step 566\n",
      "step 566\n",
      "rank 2243\n",
      "rank 2243\n",
      "rank 2243\n",
      "rank 2243\n",
      "site 329\n",
      "pending 2907\n",
      "capacity 3632\n",
      "way 38\n",
      "order 173\n",
      "strange 1334\n",
      "info 199\n",
      "could 88\n",
      "rows 271\n",
      "rows 271\n",
      "rows 271\n",
      "http 32\n",
      "request 118\n",
      "request 118\n",
      "tid 2465\n",
      "every 232\n",
      "answer 364\n",
      "k 355\n",
      "data 13\n",
      "data 13\n",
      "data 13\n",
      "data 13\n",
      "data 13\n",
      "data 13\n",
      "visualization 6307\n",
      "causes 1628\n",
      "join 394\n",
      "join 394\n",
      "join 394\n",
      "repeatedly 5955\n",
      "others 1240\n",
      "end 47\n",
      "end 47\n",
      "end 47\n",
      "end 47\n",
      "end 47\n",
      "process 244\n",
      "actual 722\n",
      "actual 722\n",
      "actual 722\n",
      "actual 722\n",
      "actual 722\n",
      "actual 722\n",
      "like 14\n",
      "hopefully 2862\n",
      "become 1983\n",
      "basically 614\n",
      "next 214\n",
      "next 214\n",
      "ending 3418\n",
      "open 194\n",
      "type 22\n",
      "type 22\n",
      "type 22\n",
      "duplicated 4328\n",
      "fe 4059\n",
      "fe 4059\n",
      "fe 4059\n",
      "base 375\n",
      "currently 312\n",
      "date 96\n",
      "date 96\n",
      "date 96\n",
      "date 96\n",
      "date 96\n",
      "date 96\n",
      "date 96\n",
      "date 96\n",
      "date 96\n",
      "date 96\n",
      "date 96\n",
      "date 96\n",
      "work 64\n",
      "previous 698\n",
      "query 86\n",
      "query 86\n",
      "query 86\n",
      "case 121\n",
      "function 7\n",
      "function 7\n",
      "ability 2611\n",
      "side 554\n",
      "steps 1180\n",
      "right 135\n",
      "start 136\n",
      "dates 1279\n",
      "intended 2546\n",
      "b 57\n",
      "b 57\n",
      "b 57\n",
      "b 57\n",
      "b 57\n",
      "likewise 9893\n",
      "else 59\n",
      "left 170\n",
      "left 170\n",
      "sim 6138\n",
      "sim 6138\n",
      "sim 6138\n",
      "select 53\n",
      "select 53\n",
      "select 53\n",
      "select 53\n",
      "select 53\n",
      "select 53\n",
      "inner 776\n",
      "essentially 2184\n",
      "comment 654\n",
      "proposed 6586\n",
      "go 262\n",
      "assign 1136\n",
      "wrong 185\n",
      "terms 1640\n",
      "create 60\n",
      "create 60\n",
      "create 60\n",
      "create 60\n",
      "create 60\n",
      "create 60\n",
      "create 60\n",
      "try 93\n"
     ]
    }
   ],
   "source": [
    "for word,index in dic.items():\n",
    "    for s in seq_x[35487]:\n",
    "        if s == index:\n",
    "            print(word + \" \" + str(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'code produc thisselect end date exhibit room placeofexhibit end date gtcurrent date minimum andr maximum locat name name exhibit orderbi end date desc column row requir second biggest one alway need second biggest one though depend count room room queri return need fourth biggest one requir get subquerythi subqueri haveselect end date exhibit room placeofexhibit end date gtcurrent date minimum andr maximum locat name name exhibit orderbi end date asc offset select count name room minimum maximum limit return queri get second last date wrong direct get second smallest instead second largest'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    9,  893,   96,   95, 9678, 1290,   96,\n",
       "         95, 7200,   95, 1760, 1427,  194,    3,    3, 9678, 2680,   96,\n",
       "         95, 1046,  102,   66,  153,  213, 5082,   32,  479,   39,  213,\n",
       "       5082,   32,  699,  311,  170, 1290, 1290,   93,   15,   39, 3775,\n",
       "       5082,   32,  153,    5, 3451,   96,   95, 9678, 1290,   96,   95,\n",
       "       7200,   95, 1760, 1427,  194,    3,    3, 9678, 2680,   96,   95,\n",
       "       1831,  842,   45,  170,    3, 1290, 1760, 1427,  625,   15,   93,\n",
       "          5,  213,  262,   95,  243,  344,    5,  213, 4258,  360,  213,\n",
       "       3549])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum 1427\n",
      "maximum 1427\n",
      "maximum 1427\n",
      "desc 1046\n",
      "row 66\n",
      "date 95\n",
      "date 95\n",
      "date 95\n",
      "date 95\n",
      "date 95\n",
      "date 95\n",
      "date 95\n",
      "date 95\n",
      "date 95\n",
      "name 3\n",
      "name 3\n",
      "name 3\n",
      "name 3\n",
      "name 3\n",
      "last 262\n",
      "smallest 4258\n",
      "direct 344\n",
      "room 1290\n",
      "room 1290\n",
      "room 1290\n",
      "room 1290\n",
      "room 1290\n",
      "count 170\n",
      "count 170\n",
      "return 15\n",
      "return 15\n",
      "limit 625\n",
      "requir 153\n",
      "requir 153\n",
      "code 9\n",
      "select 45\n",
      "end 96\n",
      "end 96\n",
      "end 96\n",
      "end 96\n",
      "end 96\n",
      "end 96\n",
      "need 39\n",
      "need 39\n",
      "wrong 243\n",
      "alway 479\n",
      "depend 311\n",
      "biggest 5082\n",
      "biggest 5082\n",
      "biggest 5082\n",
      "locat 194\n",
      "locat 194\n",
      "column 102\n",
      "though 699\n",
      "instead 360\n",
      "get 5\n",
      "get 5\n",
      "get 5\n",
      "produc 893\n",
      "largest 3549\n",
      "queri 93\n",
      "queri 93\n",
      "fourth 3775\n",
      "exhibit 9678\n",
      "exhibit 9678\n",
      "exhibit 9678\n",
      "exhibit 9678\n",
      "one 32\n",
      "one 32\n",
      "one 32\n",
      "orderbi 2680\n",
      "orderbi 2680\n",
      "gtcurrent 7200\n",
      "gtcurrent 7200\n",
      "second 213\n",
      "second 213\n",
      "second 213\n",
      "second 213\n",
      "second 213\n",
      "asc 1831\n",
      "offset 842\n",
      "minimum 1760\n",
      "minimum 1760\n",
      "minimum 1760\n",
      "subqueri 3451\n"
     ]
    }
   ],
   "source": [
    "for word,index in dic.items():\n",
    "    for s in seq_x[1]:\n",
    "        if s == index:\n",
    "            print(word + \" \" + str(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
